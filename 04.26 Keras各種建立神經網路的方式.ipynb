{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用各種不同方式寫同樣的神經網路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 初始準備\n",
    "\n",
    "Keras 可以用各種不同的深度學習套件當底層, 我們在此指定用 Tensorflow 以確保執行的一致性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND=tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd #其實不會用到\n",
    "\n",
    "from ipywidgets import interact, IntSlider, Button"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讀入建構神經網路用到的 Keras 相關函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 讀入 MNIST 數據庫\n",
    "\n",
    "MNIST 是有一堆 0-9 的手寫數字圖庫。有 6 萬筆訓練資料, 1 萬筆測試資料。它是 \"Modified\" 版的 NIST 數據庫, 原來的版本有更多資料。這個 Modified 的版本是由 LeCun, Cortes, 及 Burges 等人做的。可以參考這個數據庫的[原始網頁](http://yann.lecun.com/exdb/mnist/)。\n",
    "\n",
    "MNIST 可以說是 Deep Learning 最有名的範例, 它被 Deep Learning 大師 Hinton 稱為「機器學習的果蠅」。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 由 Keras 讀入 MNIST\n",
    "標準手段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train0, y_train0), (x_test0, y_test0) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "養成好習慣，沒事就看看資料的長相"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 輸入格式整理\n",
    "\n",
    "我們現在要用標準神經網路學學手寫辨識。原來的每筆數據是個 28x28 的矩陣 (array), 但標準神經網路只吃「平平的」, 也就是每次要 28x28=784 長的向量。因此我們要用 `reshape` 調校一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train0.reshape(60000, 28*28)\n",
    "x_test = x_test0.reshape(10000, 28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將資料線性單位化至 $[0, 1]$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train - x_train.min())/(x_train.max() - x_train.min())\n",
    "x_test = (x_test - x_test.min())/(x_test.max() - x_test.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_num = to_categorical(y_train0, 10)\n",
    "y_test_num = to_categorical(y_test0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_eo=np.ones_like(y_train0)\n",
    "y_train_eo[y_train0%2==0]=0\n",
    "y_test_eo=np.ones_like(y_test0)\n",
    "y_test_eo[y_test0%2==0]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們來準備另一個 label，將 0~9 分成偶數(y=0)、奇數 (y=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "沒事用互動模式畫個圖，十分酷炫 (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_eo = to_categorical(y_train_eo, 2)\n",
    "y_test_eo = to_categorical(y_test_eo, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 回顧 Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在第一周的時候，我們以下列的方式建立了一個具有下列設定\n",
    "\n",
    "* 使用 <span style=\"color:red;\">2</span> 個 hidden layers\n",
    "* 每個 hidden layer 用 <span style=\"color:red;\">500</span> 個神經用\n",
    "* Activation Function 唯一指名 <span style=\"color:red;\">sigmoid</span> (雖然好像有些同學測試出 <span style=\"color:red;\"> ReLU </span> 比較好用...)\n",
    "* 最後一層為類別層，有 **10** 個神經元，Activation Function 為 ``softmax``。\n",
    "\n",
    "的神經網路，建立指令是透過建立 `Sequential()` 和 `.add` 的方式逐層建立，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 648,010\n",
      "Trainable params: 648,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 建立空的神經網路學習機\n",
    "model = Sequential()\n",
    "\n",
    "# 逐層建立神經網路\n",
    "model.add(Dense(500, input_dim=784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 另一種使用 Sequential 建立神經網路的方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "觀察 ''model.layers``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x2d335921e48>,\n",
       " <keras.layers.core.Activation at 0x2d335921f28>,\n",
       " <keras.layers.core.Dense at 0x2d3359442b0>,\n",
       " <keras.layers.core.Activation at 0x2d335944908>,\n",
       " <keras.layers.core.Dense at 0x2d335944f28>,\n",
       " <keras.layers.core.Activation at 0x2d335944d30>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以發現 `model` 就是一堆神經網路***層*** 堆疊起來。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` Python\n",
    "# 建立空的神經網路學習機\n",
    "model = Sequential()\n",
    "\n",
    "# 逐層建立神經網路 \n",
    "model.add(Dense(500, input_dim=784)) # 將 `<keras.layers.core.Activation at 0xe558ef0>` 加進 model.layers\n",
    "model.add(Activation('sigmoid'))     # 將 `<keras.layers.core.Dense at 0xe58a278>` 加入 model.layers\n",
    "model.add(Dense(500))                # 將 `<keras.layers.core.Dense at 0xe58a278>` 加入 model.layers\n",
    "model.add(Activation('sigmoid'))     # 將 `<keras.layers.core.Activation at 0xe558d68>` 加入 model.layers\n",
    "model.add(Dense(10))                 # 將 `<keras.layers.core.Activation at 0xe558d68>` 加入 model.layers\n",
    "model.add(Activation('softmax'))     # 將 `<keras.layers.core.Activation at 0xe58a898>` 加入 model.layers\n",
    "\n",
    "model.summary()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "換言之，神經網路其實就是將隱藏層逐層堆疊在一起的 list，因此，我們也可以 list 的形式來建立相同的神經網路。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我們將兩個隱藏層及其 Activation Function 分別寫在 list 中，如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer = [Dense(500, input_dim=784), \n",
    "               Activation('sigmoid')]\n",
    "\n",
    "second_layer = [Dense(500), \n",
    "                Activation('sigmoid')]\n",
    "\n",
    "output_layer = [Dense(10), \n",
    "                Activation('softmax')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "從基本的 Python 資料結構中，我們知道 list 可以用 `+` 來進行合併，所以我們先來看看這三個 list 合併後的樣子。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.core.Dense at 0x2d335921940>,\n",
       " <keras.layers.core.Activation at 0x2d335921a20>,\n",
       " <keras.layers.core.Dense at 0x2d3359215c0>,\n",
       " <keras.layers.core.Activation at 0x2d335921cf8>,\n",
       " <keras.layers.core.Dense at 0x2d335921ba8>,\n",
       " <keras.layers.core.Activation at 0x2d33593a8d0>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_layer + second_layer + output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合併起來的 list 看起來就像是某個 `model.layers` 一樣，因此，我們只需將這些寫成 list 的隱藏層 `+` 起來送進 `Sequential` 中即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(first_layer + second_layer + output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 648,010\n",
      "Trainable params: 648,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q: 用 `.add` 和用 list 寫法建立的神經網路之差異？\n",
    "\n",
    "### A: 沒有任何差別，前者可以很直覺得將神經網路堆疊起來，但後者則是轉移學習 (Transfer Learning) 的方式之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 站在巨人的肩膀上 - 轉移學習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "舉例來說，如果我們今天想進行的辨識資料從辨識數字 (0~9) 變成了辨識奇偶數 (0 or 1)，而且我們希望延用之前***除了最後一層***的模型。\n",
    "\n",
    "顯然地，目前神經網路的 output 就與我們的需求不同，但我們想把前兩個隱藏層原封不動，只定義***新的最後一層***。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 648,010\n",
      "Trainable params: 648,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "all_except_last = [Dense(500, input_dim=784), \n",
    "                   Activation('sigmoid'),\n",
    "                   Dense(500), \n",
    "                   Activation('sigmoid')]\n",
    "\n",
    "output_layer = [Dense(10), \n",
    "                Activation('softmax')]\n",
    "\n",
    "model_num = Sequential(all_except_last + output_layer)\n",
    "model_num.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讀取個權重，記得要先 ``compile``，才能 ``fit``, ``evaluate``, ``predict``, ``predict_classes``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "舉例來說，如果我們今天想進行的辨識資料從辨識數字 (0~9) 變成了辨識奇偶數 (0 or 1)，而且我們希望延用之前***除了最後一層***的模型。\n",
    "\n",
    "顯然地，目前神經網路的 output 就與我們的需求不同，但我們想把前兩個隱藏層原封不動，只定義***新的最後一層***。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num.load_weights('handwriting_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 12us/step\n",
      "Loss: 0.470515\n",
      "準確率: 86.226666\n"
     ]
    }
   ],
   "source": [
    "model_num.compile(optimizer=SGD(lr=0.09), loss='categorical_crossentropy', metrics=['acc'])\n",
    "score=model_num.evaluate(x_train,y_train_num,batch_size=10000)\n",
    "print(\"Loss: %f\" %score[0])\n",
    "print(\"準確率: %f\" %(score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "但這個網路並不是重點，我們只希望***借用***某些部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們希望**借用**這個模型的某些部分。來建立 **奇、偶數辨識模型**，模型設定如下：\n",
    "\n",
    "* 使用 <span style=\"color:red;\">2</span> 個 hidden layers\n",
    "* 每個 hidden layer 用 <span style=\"color:red;\">500</span> 個神經元\n",
    "* Activation Function 唯一指名 <span style=\"color:red;\">sigmoid</span> (雖然好像有些同學測試出 <span style=\"color:red;\"> ReLU </span> 比較好用...)\n",
    "* 最後一層為類別層，有 ~~10~~ **<span style=\"color:red;\">2</span>** 個神經元，Activation Function 為 ``softmax``。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_output_layer = [Dense(2), Activation('softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 2)                 1002      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 644,002\n",
      "Trainable params: 644,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_eo = Sequential(all_except_last + new_output_layer)\n",
    "model_eo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "什麼都不做，就直接 ``evaluate``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eo.compile(optimizer=SGD(lr=0.09), loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 12us/step\n",
      "Loss: 1.218733\n",
      "準確率: 49.153333\n"
     ]
    }
   ],
   "source": [
    "score = model_eo.evaluate(x_train, y_train_eo, batch_size=10000)\n",
    "print(\"Loss: %f\" %score[0])\n",
    "print(\"準確率: %f\" %(score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練過後再看一次："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 7s 122us/step - loss: 0.2832 - acc: 0.8825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d300123d68>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model_eo.fit(x_train, y_train_eo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們再回頭看看原本模型發生什麼事情"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 14us/step\n",
      "Loss: 0.509043\n",
      "準確率: 87.436666\n"
     ]
    }
   ],
   "source": [
    "model_num.compile(optimizer=SGD(lr=0.09), loss='categorical_crossentropy', metrics=['acc'])\n",
    "score = model_num.evaluate(x_train, y_train_num, batch_size=1000)\n",
    "print(\"Loss: %f\" %score[0])\n",
    "print(\"準確率: %f\" %(score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果希望借來的模型權重，在訓練過程中不要改變，該如何做？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in all_except_last:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 2)                 1002      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 644,002\n",
      "Trainable params: 1,002\n",
      "Non-trainable params: 643,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_eo.compile(optimizer=SGD(lr=0.09), loss='categorical_crossentropy', metrics=['acc'])\n",
    "model_eo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 重新讀取**舊**模型權重 (並 evaluate)\n",
    "2. 定義新模型並凍結**舊**模型的部分\n",
    "3. 訓練新模型  \n",
    "4.回頭去看就模型的evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_num.load_weights('handwriting_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 10us/step\n",
      "Loss: 0.470515\n",
      "準確率: 86.226666\n"
     ]
    }
   ],
   "source": [
    "score = model_num.evaluate(x_train, y_train_num, batch_size=10000)\n",
    "print(\"Loss: %f\" %score[0])\n",
    "print(\"準確率: %f\" %(score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.3476 - acc: 0.8478\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3378 - acc: 0.8522\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.3340 - acc: 0.8536\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.3313 - acc: 0.8540\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.3280 - acc: 0.8568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d3001f2908>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eo.compile(optimizer=SGD(lr=0.09), loss='categorical_crossentropy', metrics=['acc'])\n",
    "model_eo.fit(x_train, y_train_eo, batch_size=1000, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 10us/step\n",
      "Loss: 0.470515\n",
      "準確率: 86.226666\n"
     ]
    }
   ],
   "source": [
    "score = model_num.evaluate(x_train, y_train_num, batch_size=10000)\n",
    "print(\"Loss: %f\" %score[0])\n",
    "print(\"準確率: %f\" %(score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 恭喜！現在的你/妳已經學會實作轉移學習了！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "雖然這個模型看起來很隨便，但轉移學習的模型**差不多**都是這樣建立的，實際上， Keras 亦提供許多被證實有良好表現且訓練好 (pre-trained) 的模型，如:\n",
    "\n",
    "* Xception\n",
    "* VGG16\n",
    "* VGG19\n",
    "* ResNet50\n",
    "* InceptionV3\n",
    "* InceptionResNetV2\n",
    "* MobileNet\n",
    "* DenseNet\n",
    "* NASNet\n",
    "\n",
    "詳細的使用方式可參考 Keras Documentation: https://keras.io/applications/\n",
    "\n",
    "但使用這些模型進行轉移學習，**可能**需要 ``Sequential`` 以外寫法，以及更多神經網路的建構技巧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 寫起來像寫數學函數的 Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在此之前，我們使用 Sequential 便足以建構大多數的神經網路，那是因為我們接觸的神經網路多為線性堆疊 (linear stack)。\n",
    "\n",
    "除了輸入層需指定 `input_dim` 外，其餘隱藏層只需宣告，那是因為 Sequential 會認定上一層的輸出這一層的輸入。\n",
    "\n",
    "因此，再建構線性堆疊的神經網路時，Sequential 便足以處理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Functional API 的使用時機"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "當神經網路模型為非線性的複雜網路結構，如：\n",
    "\n",
    "* 多重輸出-多重輸入模型 (Multi-input and multi-output models)\n",
    "  + 分歧 (branch)\n",
    "  + 合併 (merge)\n",
    "* 具重複/循環結構的模型，如: CycleGAN\n",
    "\n",
    "Sequential 便不足以建構這類複雜結構的神經網路，我們以下介紹 `Model` Fnuctional API 的使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 `Model` 的世界中，所有的神經網路層 (全連接, 卷積, 池化, RNN等) 都將視作函數來定義，因此，我們只需關心函數的輸入和輸出即可。\n",
    "\n",
    "此外，為了讓神經網路的第一層從不需要輸入 `input_dim`，我們還需引進下面這個函數來代替 `input_dim`。 (此寫法亦可用在 `Sequential`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Functional API 的函數概念"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回顧一下，我們想學習的手寫辨識模型是一個長得像這樣的函數\n",
    "\n",
    "$$\\hat{f} \\colon \\mathbb{R}^{784} \\to \\mathbb{R}^{10}$$\n",
    "\n",
    "我們希望建立一個具有兩個隱藏層的神經網路來學習這個函數，攤開來看的話，如下：\n",
    "\n",
    "$$\\mathbb{R}^{784} \\overset{f_1}{\\to} \\mathbb{R}^{500} \\overset{f_2}{\\to} \\mathbb{R}^{500} \\overset{f_3}{\\to} \\mathbb{R}^{10}$$\n",
    "\n",
    "$$x \\overset{f_1}{\\mapsto} h_1 \\overset{f_2}{\\mapsto} h_2 \\overset{f_3}{\\mapsto} y$$\n",
    "\n",
    "\n",
    "或是以簡易的圖來表示這個全連接神經網路\n",
    "\n",
    "<img src=\"plain_model.png\" alt=\"drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "其中，$f_1, f_2, f_3$ 代表的是全連結層所代表的函數，其他變數說明如下：\n",
    "\n",
    "* $x$: 代表的是輸入模型的圖片向量，為 784 維的向量。\n",
    "* $h_1$: $x$ 經過第一層隱藏層運算後得結果，即為 $f_1(x)$，為 500 維的向量。\n",
    "* $h_2$: $h_1$ 經過第二層隱藏層運算後得結果，即為 $f_2(h_1)$，為 500 維的向量。\n",
    "* $y$: $h_2$ 經過最後一層運算後得結果，即為 $f_3(h_2)$，為 10 維的向量，代表的是 $x$ 為哪個數字的機率。\n",
    "\n",
    "注意: 為了方便，我們將 `Dense(500)`, `Activation('sigmoid')` 兩個合併用 `Dense(500, activation='sigmoid')` 表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Functional API 的操作方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們沿用上圖的變數名稱來定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=(784,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_1 = Dense(500, activation='sigmoid')\n",
    "f_2 = Dense(500, activation='sigmoid')\n",
    "f_3 = Dense(10, activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，定義層前後變數之間的關係；首先，第一個變數必定以 `Input` 函數來定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_1 = f_1(x)\n",
    "h_2 = f_2(h_1)\n",
    "y = f_3(h_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "剩下的部分，就如變數說明，**幾乎**可以照著數學式輸入 $$h_1 = f_1(x), h_2 = f_2(h_1), y = f_3(h_2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在這裡，變數 $h_1, h_2, y$ 是以張量 (tensor) 類別來表示，我們可以嘗試 `print` 看看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_2:0\", shape=(?, 784), dtype=float32)\n",
      "Tensor(\"dense_34/Sigmoid:0\", shape=(?, 500), dtype=float32)\n",
      "Tensor(\"dense_35/Sigmoid:0\", shape=(?, 500), dtype=float32)\n",
      "Tensor(\"dense_36/Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "<keras.layers.core.Dense object at 0x000002D31BA895F8>\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(h_1)\n",
    "print(h_2)\n",
    "print(y)\n",
    "print(f_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，透過 `Model` 將一個模型的輸入/輸出包裝起來，建立模型的過程就完成了！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 648,010\n",
      "Trainable params: 648,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Model(x,y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一樣的，當模型 compile 之後，便可以進行資料的訓練、預測等等，請有興趣的同學讀入 MNIST 手寫辨識之料後，自行完成這個模型的訓練。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=SGD(lr=0.1), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x_train, y_train, batch_size=100, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "雖然 summary 少了很多東西，但模型架構和之前做的沒有差異，所以可以安心讀入之前訓練好的權重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('handwriting_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 11us/step\n",
      "Loss: 0.021306\n",
      "準確率: 86.226666\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_train, y_train_num, batch_size=10000)\n",
    "print(\"Loss: %f\" %score[0])\n",
    "print(\"準確率: %f\" %(score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 小結論\n",
    "Functional API 的操作流程如下：\n",
    "1. 將層定義成明確的函數\n",
    "2. 透過層函數將變數連接\n",
    "3. 定義神經網路的輸入與輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 非線性堆疊模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 如果建立具分歧及合併結構的神經網路模型呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate, add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，假設我們希望在模型之間增加一個分歧，且這個分歧在模型的輸出會合併，則神經網路的結構會變成：\n",
    "\n",
    "<img src=\"branch-and-merge.png\" alt=\"drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "此模型為單一輸入、多重輸出的模型，是分歧模型最容易處理的一種。\n",
    "\n",
    "其中，$f_1, f_2$ 同之前，$f_4:\\mathbb{R}^{500}\\to\\mathbb{R}^{500}$ 的全連接層，但 `Activation` 改用 `ReLu`。\n",
    "\n",
    "需注意的是，由於 $f_3$ 的定義域改變，為 $\\mathbb{R}^{500}\\times\\mathbb{R}^{500}\\to\\mathbb{R}^{10}$ 函數，所以需要重新定義。\n",
    "\n",
    "* $x$: 代表的是輸入模型的圖片向量，為 784 維的向量。\n",
    "* $h_1$: $x$ 經過 $f_1$ 隱藏層運算後得結果，即為 $f_1(x)$，為 500 維的向量。\n",
    "* $h_2$: $h_1$ 經過 $f_2$ 隱藏層運算後得結果，即為 $f_2(h_1)$，為 500 維的向量。\n",
    "\n",
    "* $z$: $h_1$ 經過 $f_4$ 運算後得結果，即為 $f_4(h_1)$，為 500 維的向量。\n",
    "* $y$: $h_2$ 和 $z$ 經過新的 $f_3$ 運算後得結果，即為 $f_3(h_1, z)$，為 10 維的向量，代表的是 $x$ 為哪個數字的機率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因為上面已將 $f_4$ 及 $z$ 以外的變數定義好，我們只需定義 $f_3$, $f_4$ 及 $z$ 即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_3 = Dense(10, activation='softmax')\n",
    "f_4 = Dense(500, activation='relu')\n",
    "z = f_4(h_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，再將 $y = f_3(h_2, z)$ 定義好，就會發現......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此段程式碼為錯誤範例\n",
    "#y = f_3(h_2, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "聰明的你/妳，可能會想到，函數的寫法是一次送進一個變數，那我們將 $h_3$ 和 $z$ 寫成 `list` 的形式，應該就可以送進去 $f_3$ 了吧？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此段程式碼為錯誤範例\n",
    "#y = f_3([h_2, z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "會發現這樣也沒辦法成功。其實正確的作法是，先將 $h_2$ 與 $z$ 透過 `concatenate` 接在一起，再送進新的 $f_3$ 裡。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在這裡，我們將 $h_2$ 與 $z$ `concatenate` 接在一起，稱做 $u$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = concatenate([h_2, z])\n",
    "y = f_3(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concatenate_3/concat:0\", shape=(?, 1000), dtype=float32)\n",
      "Tensor(\"dense_37/Softmax:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(u)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "換句話說，模型其實是這樣畫的\n",
    "\n",
    "<img src=\"branch-and-merge_final.png\" alt=\"drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "其中，`concatenate` 是將不同的變數**接**在一起，這裡面並沒有進行任何涉及權重的運算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再透過 `Model` 將模型的輸入和輸出包裝起來，即可將模型建構完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 500)          392500      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 500)          250500      dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 500)          250500      dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 1000)         0           dense_35[0][0]                   \n",
      "                                                                 dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 10)           10010       concatenate_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 903,510\n",
      "Trainable params: 903,510\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(x, y)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 小結論\n",
    "Branch-and-Merge 的注意要點如下：\n",
    "1. 每一層分別定義成函數\n",
    "2. 分歧結構: 實就是透過新的函數來定義新的變數，無特別注意事項。\n",
    "3. 合併結構: 要合併前，將所有要進入的變數都合併起來，才能進行之後的運算。\n",
    "\n",
    "常見應用:\n",
    "1. 多重輸入-多重輸出模型。\n",
    "2. 當層函數為 convolution 時，這樣的技巧可以實現 U-net 上的重要結構 multi-resolution fusion (多解析度融合，又稱 MRF)。\n",
    "3. ResNet 上的重要結構 skip connection (跳躍式傳遞)，亦可透過分歧-合併來實現，只是 ResNet 使用的是 `add` 而非 `concatenate`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 自定義的不具可訓練權重之神經網路層\n",
    "這裡，我們將進行這單元最後一個重要的神經網路建構技巧 - 自定義神經網路層 (不具可訓練權重)\n",
    "\n",
    "** 具有可訓練重的自定義層牽扯到 TensorFlow 及 Python 類別的撰寫，若有興趣可參考: https://keras.io/layers/writing-your-own-keras-layers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我們需要引入 `Lambda` 這個函數，透過 `Lambda` 函數，我們可以將 Python 上的 function，包裝成 Keras 上的 layer。\n",
    "\n",
    "此外，我們需要引進後端所使用的套件 (此處為 TensorFlow)，並使用裡面的運算進行 function 的撰寫。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先，我們透過 backend 來定義一個簡單的 function，作用是對輸入取平均，程式碼如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，我們將一個 numpy array 送進這個函式，看看會發生什麼事。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 此段程式碼為錯誤範例\n",
    "y=K.mean(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你/妳會發現，這邊的函式不接受 numpy array 的類型作為輸入，這是因為 TensorFlow 有自定義的類型，因此，在這邊我們沒辦法直接使用這個函式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們透過 `Lambda` ，將上述函式包裝成一個神經網路層。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_mean= Lambda(K.mean,output_shape=[1,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "lambda_4 (Lambda)            (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Model(x,keras_mean(x))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此時，下述程式碼可以建構出一個將指定長度的資料取平均的神經網路。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13768007], dtype=float32)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以發現，這樣的神經網路是不具有訓練權重的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13768007202881152"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:1].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "記得，在使用前記得先 compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，我們將 `[1, 2, 3, 4]` 送進這個神經網路，看看神經網路的輸出是否為這個向量的**平均。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以發現，將 `[1, 2, 3, 4]` 轉成 Numpy array 送進神經網路**預測**後，答案是 `2.5`，即為 (1+2+3+4)/4，確實是平均。\n",
    "\n",
    "我們也可以一次送進多筆資料進行平均的計算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加碼: 具抽樣功能的神經網路層\n",
    "\n",
    "輸入為 $(\\mu, s)$ ，$\\mu=(\\mu_1,\\cdots,\\mu_n)$ 和 $s=(s_1,\\cdots,s_n)$ 各自為 $n$ 維向量。\n",
    "\n",
    "我們希望神經網路層輸出為服從 $N(\\mu, e^{s}I_n)$ 的 $n$ 維向量，換言之，我們希望建構的神經網路其實是一個抽樣函數。\n",
    "\n",
    "** 由於神經網路的輸入輸出經常沒有限制，為了讓 $s$ 具有變異數的非負特性，我們考慮 $e^{s}$ 作為變異數；換言之，$s$ 為 log-variance。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假設我們想進行抽樣的維度為 `sampling_dim`，則一個具抽樣函數功能的神經網路可由下述方式建構。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_dim = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這裡使用到常態分配的線性特性來定義函數，亦即\n",
    "\n",
    "$$X\\sim N(0, 1)\\Rightarrow \\mu+\\sigma X\\sim N(\\mu, \\sigma^2)$$\n",
    "\n",
    "\n",
    "若不熟機率論的同學，可以詢問助教。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    epsilon = K.random_normal(shape=(sampling_dim,), mean=0., stddev=1)\n",
    "    return z_mean + K.exp(z_log_var / 2) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_layer = Lambda(sampling, output_shape=(sampling_dim,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Input(shape=(sampling_dim,))\n",
    "s = Input(shape=(sampling_dim,))\n",
    "\n",
    "z = sample_layer([m, s])\n",
    "\n",
    "sample_model = Model([m, s], z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 2)            0           input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sample_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "透過下面的指令，我們每次可以抽樣出一服從上述要求常態分配之隨機向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均為 (9, 3)\n"
     ]
    }
   ],
   "source": [
    "test_mean = np.random.randint(10, size=sampling_dim).reshape(1, 2)\n",
    "test_log_var = np.array([[0, 0]])\n",
    "\n",
    "print(\"平均為 (%d, %d)\" %(test_mean[0][0], test_mean[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11.533432 ,  2.8886735]], dtype=float32)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_model.predict([test_mean, test_log_var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "來和 Numpy 上的抽樣函數進行比較吧~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_samples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_sample = np.random.multivariate_normal(test_mean[0], np.identity(2), size=num_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "kears_sample = np.zeros((num_of_samples, 2))\n",
    "for i in range(num_of_samples):\n",
    "    kears_sample[i] = sample_model.predict([test_mean, test_log_var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Normal Random Samples using Keras/Numpy')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(kears_sample[:, 0], kears_sample[:, 1], 'ro')\n",
    "plt.plot(np_sample[:, 0], np_sample[:, 1], 'o')\n",
    "plt.legend(['Keras', 'Numpy'])\n",
    "plt.title('Normal Random Samples using Keras/Numpy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 恭喜你，完成所有建立 Variational Autoencoder 所需的重要技巧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variational Autoencoder (VAE) 是一個重要的非監督式學習模型，具體應用的場合為特徵抽取/資料壓縮及還原，為影像處理中常見的模型之一。\n",
    "\n",
    "在建立 VAE中，需要三個重要技巧:\n",
    "* 分歧-合併\n",
    "* 自定義函數 (抽樣函數)\n",
    "* 自定義損失函數\n",
    "\n",
    "雖然不知道之後課程會不會用到，但多學點總是好的 : )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
